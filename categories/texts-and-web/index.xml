<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Texts and Web | DTAI</title><link>https://dtai.cs.kuleuven.be/stories/categories/texts-and-web/</link><atom:link href="https://dtai.cs.kuleuven.be/stories/categories/texts-and-web/index.xml" rel="self" type="application/rss+xml"/><description>Texts and Web</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 23 Mar 2020 23:52:28 +0100</lastBuildDate><image><url>img/map[gravatar:%!s(bool=false) shape:circle]</url><title>Texts and Web</title><link>https://dtai.cs.kuleuven.be/stories/categories/texts-and-web/</link></image><item><title>Can computers create jokes?</title><link>https://dtai.cs.kuleuven.be/stories/post/thomas-winters/computational_humor_mopjesbot/</link><pubDate>Mon, 23 Mar 2020 23:52:28 +0100</pubDate><guid>https://dtai.cs.kuleuven.be/stories/post/thomas-winters/computational_humor_mopjesbot/</guid><description>&lt;h3 id="computational-humor">Computational humor&lt;/h3>
&lt;p>Can computers be funny?
Certainly your virtual assistant (e.g. &lt;em>Siri&lt;/em> or &lt;em>Alexa&lt;/em>) is able to tell a joke if you ask for one, but these are of course pre-written, human-made jokes.
One might wonder if computers are already advanced enough to understand how to construct good jokes.
And if they can write jokes, can they do this in any language and about any topic?
And could they tailor their sense of humor to users?&lt;/p>
&lt;p>Many researchers have already looked into humor generation algorithms.
Recent popular neural networks approaches seem to indicate that
writing good jokes is
&lt;a href="https://towardsdatascience.com/teaching-gpt-2-a-sense-of-humor-fine-tuning-large-transformer-models-on-a-single-gpu-in-pytorch-59e8cec40912" target="_blank" rel="noopener">still far off&lt;/a>.
Most of the funny things computers create using neural networks,
&lt;a href="https://aiweirdness.com/books" target="_blank" rel="noopener">seem to mostly occur on accident&lt;/a>.&lt;/p>
&lt;p>Further in the past, however, more symbolic approaches have been used to generate subjectively better jokes.
Researchers created programs to, for example,
&lt;a href="http://joking.abdn.ac.uk/webversion/welcome.php" target="_blank" rel="noopener">generate punning riddles&lt;/a>,
&lt;a href="http://www.infoivy.com/2013/09/big-data-what-joke-generator-that-is.html" target="_blank" rel="noopener">create analogy jokes&lt;/a>
and
&lt;a href="https://www.popsci.com/technology/article/2011-04/thats-what-she-said-software-recognizes-pervy-double-entendres-automatically/" target="_blank" rel="noopener">detect double entendres&lt;/a>.
These programs usually define some rules that constitute a funny joke, and then fill in the slots randomly.
For example, the
&lt;a href="%28http://joking.abdn.ac.uk/webversion/welcome.php%29">STANDUP punning riddle generator&lt;/a> might generate a joke like:&lt;/p>
&lt;blockquote>
&lt;p>What is the difference between a pretty glove and a silent cat?&lt;/p>
&lt;p>One is a cute mitten, the other is a mute kitten.&lt;/p>
&lt;/blockquote>
&lt;p>To create such a joke, the generator uses templates.
Template can be seen as sentences with holes, which are later filled in by following certain rules.
For example, for the above joke, the template would be the same as the joke, but without the words &lt;em>pretty&lt;/em>, &lt;em>glove&lt;/em>, &lt;em>silent&lt;/em>, &lt;em>cat&lt;/em>, &lt;em>cute&lt;/em>, &lt;em>mitten&lt;/em>, &lt;em>mute&lt;/em> and &lt;em>kitten&lt;/em>:&lt;/p>
&lt;blockquote>
&lt;p>What is the difference between a &lt;strong>A&lt;/strong> &lt;strong>B&lt;/strong> and a &lt;strong>C&lt;/strong> &lt;strong>D&lt;/strong>?&lt;/p>
&lt;p>One is a &lt;strong>E&lt;/strong> &lt;strong>F&lt;/strong>, the other is a &lt;strong>G&lt;/strong> &lt;strong>H&lt;/strong>.&lt;/p>
&lt;/blockquote>
&lt;p>These holes are then related to each other using rules, which then fill the holes with appropriate words.
For the above template, there are constraints enforcing that &lt;strong>E&lt;/strong> and &lt;strong>G&lt;/strong> end with the same sound, and so should &lt;strong>F&lt;/strong> and &lt;strong>H&lt;/strong>.
Similarly, &lt;strong>E&lt;/strong> and &lt;strong>H&lt;/strong> start with the same sound, and so do &lt;strong>F&lt;/strong> and &lt;strong>G&lt;/strong>.
To create the question of the riddle, four pairs of synonyms are required, namely &lt;strong>A&lt;/strong> should be a synonym of &lt;strong>E&lt;/strong>, &lt;strong>B&lt;/strong> of &lt;strong>F&lt;/strong> and so on.
In a way, the generator is playing
&lt;a href="http://www.madlibs.com/" target="_blank" rel="noopener">Mad Libs&lt;/a> with itself, but enforcing slightly more logic in the relations between the words.&lt;/p>
&lt;p>&lt;img src="mopjesbot_drawing.jpg" alt="mopjesbot">&lt;/p>
&lt;h3 id="teaching-joke-patterns">Teaching joke patterns&lt;/h3>
&lt;p>So while it might be hard to make a computer come up with a broad range of clever jokes completely from scratch,
we can teach them how to generate specific types of jokes.
However, while many English language resources exist, not all languages possess such plentiful language resources for enforcing and checking linguistic constraints.
Another problem is that most joke generators use static data sources (e.g. an internal dictionary), and are thus unable to create jokes about topics that are not included in this data, unless they are manually updated.
Old joke generators might thus not be able to make jokes about new music artists or politicians.&lt;/p>
&lt;p>We created
&lt;a href="https://twitter.com/MopjesBot" target="_blank" rel="noopener">bot&lt;/a> for generating Dutch &lt;em>&amp;ldquo;Kermit de Kikker&amp;rdquo;&lt;/em> punning riddles, using limited Dutch language resources,
namely
&lt;a href="https://nl.wikipedia.org/" target="_blank" rel="noopener">Wikipedia&lt;/a>, a
&lt;a href="https://www.mijnwoordenboek.nl/synoniem.php" target="_blank" rel="noopener">thesaurus&lt;/a> (or
&lt;a href="https://nl.wiktionary.org/wiki/Hoofdpagina" target="_blank" rel="noopener">Wiktionary&lt;/a>),
&lt;a href="https://www.mijnwoordenboek.nl/rijmwoordenboek/" target="_blank" rel="noopener">rhyming dictionary&lt;/a> and
&lt;a href="https://www.ushuaia.pl/hyphen/?ln=nl" target="_blank" rel="noopener">hyphenation&lt;/a>.
All these resources tend to be available online for most of the popular languages.
The classic &lt;em>&amp;ldquo;Kermit de Kikker&amp;rdquo;&lt;/em> (&lt;em>Dutch for
&lt;a href="https://en.wikipedia.org/wiki/Kermit_the_Frog" target="_blank" rel="noopener">Kermit the Frog&lt;/a>&lt;/em>) joke is based on finding rhymes of &lt;em>Kikker&lt;/em> based on what the riddle suggest.
For example:&lt;/p>
&lt;blockquote>
&lt;p>Het is groen en het plakt?&lt;/p>
&lt;p>Kermit de Sticker&lt;/p>
&lt;/blockquote>
&lt;p>In English, this joke says: &lt;em>&amp;ldquo;It&amp;rsquo;s green and adhesive? Kermit the Sticker&amp;rdquo;&lt;/em>.
This is a joke because &lt;em>&amp;ldquo;sticker&amp;rdquo;&lt;/em> is a rhyme of &lt;em>&amp;ldquo;kikker&amp;rdquo;&lt;/em>, Dutch for &lt;em>&amp;ldquo;frog&amp;rdquo;&lt;/em>.
Usually, this joke is followed by a large succession of similar jokes about Kermit, e.g.&lt;/p>
&lt;blockquote>
&lt;p>Het is groen en is pyromaan?&lt;/p>
&lt;p>Kermit de Fikker&lt;/p>
&lt;/blockquote>
&lt;p>As you might have realised, this is something we can teach computers to generate for us.
But why stick with only making jokes about &lt;em>Kermit de Kikker&lt;/em> when you can insert any name?
Given the name &lt;em>Kanye West&lt;/em> as input, it would perform the following steps:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>
&lt;a href="https://www.rhymezone.com/r/rhyme.cgi?Word=west&amp;amp;typeofrhyme=perfect&amp;amp;org1=syl&amp;amp;org2=l&amp;amp;org3=y" target="_blank" rel="noopener">Find a rhyme&lt;/a>
on the last word with the same number of syllables, e.g. &lt;em>rest&lt;/em> .
If the last word of the input has multiple syllables, look for rhymes on any combination of consequent syllables.
Prefer more common words using a word frequency list, if this is available in the language of choice.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Replace the relevant syllables of the input name with the rhyme word, e.g. Kanye Rest.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Use
&lt;a href="https://wikipedia.org" target="_blank" rel="noopener">Wikipedia&lt;/a> to find a nice description of the entity with the input name.
This is not that hard to extract from the Wikipedia page, since the introduction usually start with &lt;em>[entity_name] &lt;strong>is/was/are&lt;/strong> [explanation]&lt;/em>.
By taking the part after the &lt;em>&amp;ldquo;to be&amp;rdquo;&lt;/em> verb, and until any punctuation or start of clause, the program can distill a brief description.
For example, it would describe
&lt;a href="https://en.wikipedia.org/wiki/Kanye_West" target="_blank" rel="noopener">Kanye West&lt;/a> as &lt;em>an American rapper&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It now only has to describe the rhyme word to complete the pun riddle.
To achieve this, either a
&lt;a href="https://www.thesaurus.com/browse/rest" target="_blank" rel="noopener">thesaurus&lt;/a> (for short descriptions),
or segments from
&lt;a href="https://en.wiktionary.org/wiki/rest" target="_blank" rel="noopener">Wiktionary&lt;/a> (for longer, more interesting descriptions) could be used.
The algorithm should however make sure that the description do not contain the word to guess itself, since that would spoil the fun.
The word frequency table could also be used to choose less common (and thus more specific) descriptive words.
For example, it could describe &lt;em>rest&lt;/em> as &lt;em>&amp;ldquo;relief from work&amp;rdquo;&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Now it can fill all these words into the the template, to create the following joke:&lt;/p>
&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>It&amp;rsquo;s an American rapper and is relief from work?&lt;/p>
&lt;p>Kanye Rest&lt;/p>
&lt;/blockquote>
&lt;p>These jokes tend to become more interesting once you have multiple of them, as they turn into a fun guessing game.
Luckely, given that we completely automated the generation process, the described program can easily generate many more jokes about this person.&lt;/p>
&lt;p>We build a Twitterbot, called
&lt;a href="https://twitter.com/MopjesBot" target="_blank" rel="noopener">MopjesBot&lt;/a>, that generates five unique jokes using this schema on a daily basis.
It first checks the news for articles, then filters out articles about too sensitive topics, and finally picks the name that occurs most in these articles.
The complete overview of all steps it follows to generate these jokes are summarised in the diagram below:&lt;/p>
&lt;p>&lt;img src="mopjesbot_flow.png" alt="mopjesbot overview">&lt;/p>
&lt;p>This system is thus able to generate jokes following a specific template and schema,
but also nudges the jokes to have a higher probability of having certain characteristics (e.g. common or less common words in certain template &amp;ldquo;holes&amp;rdquo;).&lt;/p>
&lt;h3 id="learning-what-constitutes-a-joke">Learning what constitutes a joke&lt;/h3>
&lt;p>While it&amp;rsquo;s wonderful that we can already make computers generate jokes using templates and schemas, implementing such joke generators requires a large amount of human effort.
The computer is also not really gaining insights into humor itself, but rather the human giving the machine explicit insights into a specific type of joke.&lt;/p>
&lt;p>So, could it learn these insights by itself?
This is one task we want to tackle in the future, which can be subdivided in multiple parts:&lt;/p>
&lt;ul>
&lt;li>can we automatically extract meaningful relations between words of a good joke?&lt;/li>
&lt;li>can we find out which jokes are better than others by learning probabilities, and use these to &amp;ldquo;nudge&amp;rdquo; the generators into generating better jokes?&lt;/li>
&lt;/ul>
&lt;p>The former is something we have
&lt;a href="https://www.researchgate.net/publication/325432136_Automatic_Joke_Generation_Learning_Humor_from_Examples" target="_blank" rel="noopener">explored in the past&lt;/a>, and are still actively investigating.
The latter task could be achieve using preference learning.
&lt;a href="https://en.wikipedia.org/wiki/Preference_learning" target="_blank" rel="noopener">Preference learning&lt;/a> is a task where given a set of two data points, the algorithm has to predict which one is preferred by a human.
This could then be used to find optimal parameters to contruct a joke that a particular user or group of users might like.&lt;/p>
&lt;p>The future of automatic joke generation is thus exciting, and still full of opportunities.
We can already create joke generation algorithms by hand and getting close to learn them automatically.
In the future, we might not need to listen to pre-written jokes told by Siri any more, and instead could enjoy personalised, generated humor.
Or, as our algorithm might say:&lt;/p>
&lt;blockquote>
&lt;p>It&amp;rsquo;s a branch of artificial intelligence which uses computers in humor research and is a claim of questionable accuracy?&lt;/p>
&lt;p>Computational Rumor&lt;/p>
&lt;/blockquote></description></item></channel></rss>